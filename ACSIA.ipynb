{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "aai.settings.api_key = \"46f3fc0a6e364888acf89978f15a5d24\"\n",
    "transcriber = aai.Transcriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript = transcriber.transcribe(\"onlymp3.to - Speech recognition in Python made easy Python Tutorial-YdYTSxEW5bA-192k-1700264266.mp3\")\n",
    "transcript.audio_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi everyone, this is Patrick from Assemblyai.\n",
      "And in this video we're going to take a look at our Python SDK.\n",
      "So I show you how you can transcribe and analyze audio data with just a few lines of code.\n",
      "So let's get started.\n",
      "So first let's set up the Python SDK and you can find this on GitHub by the way.\n",
      "And to install this you can simply say PIP, install assemblyai.\n",
      "And now let's jump to the code.\n",
      "And the first thing we want to do is import and then you want to set your API key and you can do this by calling AAI settings API key and here set your key.\n",
      "You can get one for free on our website.\n",
      "The link will be in the description below.\n",
      "Or as a second way, you could also set this as a environment variable that has to be called Assemblyai ApI Key.\n",
      "For example, if I open my terminal I could hear export assemblyai API key and set this as key.\n",
      "And then you don't need this line, but here we want to do it with the first option.\n",
      "Next, let's learn how we can transcribe files with the SDK.\n",
      "So for this we create a transcriber instance and then we can call transcriber transcribe.\n",
      "And this works with either a URL to a file, or we can also simply pass in a local file.\n",
      "So here I prepared a local MP3 file and now this will start the transcription and this function will block until the transcription is completed.\n",
      "And then finally we can simply call transcript text to see the transcribe text.\n",
      "So let's comment this one out and use the local file.\n",
      "And let's run this and see if it works.\n",
      "And as you can see here, we get the transcription.\n",
      "Now this transcript object is of the class transcriber transcript, and you can do many more things with this.\n",
      "For example, you could check the audio duration, or you can get the single sentences by calling transcript, get sentences, and then we can iterate over them and print the text again.\n",
      "And as you can see here we get the single sentences, or instead of the sentences you can also call transcript, get paragraphs and then iterate over them.\n",
      "And here we get the single paragraphs.\n",
      "You can also do a word search.\n",
      "For example you can call transcript word search and here as a list you can pass in all the words you want to search for.\n",
      "And then you get the matches back so we can iterate over them.\n",
      "And then for example we can print found, match text and then match count.\n",
      "And then you can also get the timestamps for each word and also the indices.\n",
      "So let's run this and see if it works.\n",
      "And as you can see, it found President two times.\n",
      "And here we get the corresponding timestamp and the indices.\n",
      "And it also found people one time.\n",
      "And here is the corresponding timestamp.\n",
      "Now let's learn how we can transcribe files asynchronous.\n",
      "So as I've mentioned, the transcriber transcribe function will block until the result is finished.\n",
      "So we can also call transcribeasync.\n",
      "And now this will return a future object from the async I O library.\n",
      "So let's run this, and this will immediately return.\n",
      "And then we can do some other stuff.\n",
      "So as you can see, this immediately returns and we can see the state is running.\n",
      "And then at a later time, for example, we can check if the future is done.\n",
      "And then we can get the transcript by calling future result.\n",
      "And now this is again the same transcript object that we've seen before.\n",
      "For example, here we can now print transcript text.\n",
      "And by now, hopefully the state is already completed.\n",
      "So now here we should see the text.\n",
      "And as you can see, this worked.\n",
      "So this is how you can transcribe files asynchronously.\n",
      "Now let's learn how you can configure transcription parameters and also trigger different audio intelligence features.\n",
      "So for this you can set up a transcription config.\n",
      "And here you can set different parameters.\n",
      "For example, you can set punctuate should be false and formatting should be false.\n",
      "And then you pass this config when you set up your transcriber object.\n",
      "So this is the first way how you could do it.\n",
      "You can also directly call this on the transcribe function.\n",
      "Now we do it with the global configuration.\n",
      "And then again you call transcriber transcribe.\n",
      "And now we print the transcription text.\n",
      "And let's run this and wait until this is done.\n",
      "And here again it prints the transcript, but this time without punctuation and formatting.\n",
      "You can also use the transcription config to set up different audio intelligence features.\n",
      "For example, let's use the summarization feature.\n",
      "So when we set up the transcription config, here we set summarization equals true.\n",
      "And then you could also optionally set the summary model and the summary type.\n",
      "And here we set this to informative and then to bullets.\n",
      "So this is the second way how we can use it.\n",
      "We can directly call this on the transcribe function, and then it will overwrite the global config.\n",
      "And then since we set summarization equals true, we can then access transcript summary.\n",
      "So let's run this, and as you can see now we get a summary with two bullet points.\n",
      "So this was a short guide how you can get started with the Python SDK.\n",
      "I recommend to check out the documentation to see what else you can do with it, and I hope you enjoyed this video.\n",
      "So if so, then please leave us a like and consider subscribing to our channel.\n",
      "And then I hope to see you next time.\n",
      "Bye.\n"
     ]
    }
   ],
   "source": [
    "transcript = transcriber.transcribe(\"onlymp3.to - Speech recognition in Python made easy Python Tutorial-YdYTSxEW5bA-192k-1700264266.mp3\")\n",
    "\n",
    "oraciones= transcript.get_sentences()\n",
    "\n",
    "for sentence in oraciones:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi everyone, this is Patrick from Assemblyai. And in this video we're going to take a look at our Python SDK. So I show you how you can transcribe and analyze audio data with just a few lines of code. So let's get started. So first let's set up the Python SDK and you can find this on GitHub by the way.\n",
      "And to install this you can simply say PIP, install assemblyai. And now let's jump to the code. And the first thing we want to do is import and then you want to set your API key and you can do this by calling AAI settings API key and here set your key. You can get one for free on our website. The link will be in the description below.\n",
      "Or as a second way, you could also set this as a environment variable that has to be called Assemblyai ApI Key. For example, if I open my terminal I could hear export assemblyai API key and set this as key. And then you don't need this line, but here we want to do it with the first option. Next, let's learn how we can transcribe files with the SDK. So for this we create a transcriber instance and then we can call transcriber transcribe.\n",
      "And this works with either a URL to a file, or we can also simply pass in a local file. So here I prepared a local MP3 file and now this will start the transcription and this function will block until the transcription is completed. And then finally we can simply call transcript text to see the transcribe text. So let's comment this one out and use the local file. And let's run this and see if it works.\n",
      "And as you can see here, we get the transcription. Now this transcript object is of the class transcriber transcript, and you can do many more things with this. For example, you could check the audio duration, or you can get the single sentences by calling transcript, get sentences, and then we can iterate over them and print the text again. And as you can see here we get the single sentences, or instead of the sentences you can also call transcript, get paragraphs and then iterate over them. And here we get the single paragraphs.\n",
      "You can also do a word search. For example you can call transcript word search and here as a list you can pass in all the words you want to search for. And then you get the matches back so we can iterate over them. And then for example we can print found, match text and then match count. And then you can also get the timestamps for each word and also the indices.\n",
      "So let's run this and see if it works. And as you can see, it found President two times. And here we get the corresponding timestamp and the indices. And it also found people one time. And here is the corresponding timestamp.\n",
      "Now let's learn how we can transcribe files asynchronous. So as I've mentioned, the transcriber transcribe function will block until the result is finished. So we can also call transcribeasync. And now this will return a future object from the async I O library. So let's run this, and this will immediately return.\n",
      "And then we can do some other stuff. So as you can see, this immediately returns and we can see the state is running. And then at a later time, for example, we can check if the future is done. And then we can get the transcript by calling future result. And now this is again the same transcript object that we've seen before.\n",
      "For example, here we can now print transcript text. And by now, hopefully the state is already completed. So now here we should see the text. And as you can see, this worked. So this is how you can transcribe files asynchronously.\n",
      "Now let's learn how you can configure transcription parameters and also trigger different audio intelligence features. So for this you can set up a transcription config. And here you can set different parameters. For example, you can set punctuate should be false and formatting should be false. And then you pass this config when you set up your transcriber object.\n",
      "So this is the first way how you could do it. You can also directly call this on the transcribe function. Now we do it with the global configuration. And then again you call transcriber transcribe. And now we print the transcription text.\n",
      "And let's run this and wait until this is done. And here again it prints the transcript, but this time without punctuation and formatting. You can also use the transcription config to set up different audio intelligence features. For example, let's use the summarization feature. So when we set up the transcription config, here we set summarization equals true.\n",
      "And then you could also optionally set the summary model and the summary type. And here we set this to informative and then to bullets. So this is the second way how we can use it. We can directly call this on the transcribe function, and then it will overwrite the global config. And then since we set summarization equals true, we can then access transcript summary.\n",
      "So let's run this, and as you can see now we get a summary with two bullet points. So this was a short guide how you can get started with the Python SDK. I recommend to check out the documentation to see what else you can do with it, and I hope you enjoyed this video. So if so, then please leave us a like and consider subscribing to our channel. And then I hope to see you next time.\n",
      "Bye.\n"
     ]
    }
   ],
   "source": [
    "transcript = transcriber.transcribe(\"onlymp3.to - Speech recognition in Python made easy Python Tutorial-YdYTSxEW5bA-192k-1700264266.mp3\")\n",
    "\n",
    "oraciones= transcript.get_paragraphs()\n",
    "\n",
    "for parrafo in oraciones:\n",
    "    print(parrafo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, guys, listen. I don't know what can I say in this audio, but at least this audio can be useful for your artificial intelligence. So let's do it. I don't know. You can do it.\n",
      "I believe in you. And greetings for Ramirus and Galoya Tobya Miman. Why I start to talking in Spanish? This audio supposed to be all in English. So all remain the.\n"
     ]
    }
   ],
   "source": [
    "transcript = transcriber.transcribe(\"WhatsApp Audio 2023-11-17 at 6.46.00 PM.mp4\")\n",
    "\n",
    "oraciones= transcript.get_paragraphs()\n",
    "\n",
    "for parrafo in oraciones:\n",
    "    print(parrafo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andre\\Downloads\\Inteligencia Artificial\\Proyecto IA\\ACSIA.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Downloads/Inteligencia%20Artificial/Proyecto%20IA/ACSIA.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m arg_list\u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39margv\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Downloads/Inteligencia%20Artificial/Proyecto%20IA/ACSIA.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m filename\u001b[39m=\u001b[39m arg_list[\u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andre/Downloads/Inteligencia%20Artificial/Proyecto%20IA/ACSIA.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m language\u001b[39m=\u001b[39m arg_list[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andre/Downloads/Inteligencia%20Artificial/Proyecto%20IA/ACSIA.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m upload_endpoint\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://api.assemblyai.com/v2/upload\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andre/Downloads/Inteligencia%20Artificial/Proyecto%20IA/ACSIA.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m headers\u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mauthorizathion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m46f3fc0a6e364888acf89978f15a5d24\u001b[39m\u001b[39m\"\u001b[39m}\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "arg_list= sys.argv\n",
    "filename= arg_list[1]\n",
    "language= arg_list[2]\n",
    "\n",
    "upload_endpoint= \"https://api.assemblyai.com/v2/upload\"\n",
    "headers= {\"authorizathion\": \"46f3fc0a6e364888acf89978f15a5d24\"}\n",
    "\n",
    "def read_file(filename, chunk_size=5242880):\n",
    "  with open(filename, 'rb') as _file:\n",
    "    while True:\n",
    "      data= _file.read(chunk_size)\n",
    "      if not data:\n",
    "        break\n",
    "      yield data \n",
    "\n",
    "upload_response= requests.post(upload_endpoint, headers= headers, data= read_file())\n",
    "print(upload_response.json())\n",
    "audio_url= upload_response.json()['upload_url']\n",
    "\n",
    "transcription_endpoint= \"https://api.assemblyai.com/v2/transcript\"\n",
    "\n",
    "json= {\"audio_url\":audio_url, \n",
    "       \"language_code\":language}\n",
    "\n",
    "transcription_response= requests.post(transcription_endpoint, headers= headers, json= json)\n",
    "print(transcription_response,json())\n",
    "\n",
    "transcript_id= transcription_response.json()['id']\n",
    "\n",
    "polling_endpoint= transcription_endpoint + \"/\" + transcript_id\n",
    "\n",
    "while True:\n",
    "  polling_response= requests.get(polling_endpoint, headers= headers)\n",
    "  polling_response.json()['status']\n",
    "\n",
    "  if status == \"completed\":\n",
    "\n",
    "    with open(language + \"transcription.txt\", \"w\") as f:\n",
    "      f.write(polling_response.json()['text'])\n",
    "\n",
    "  elif status == \"error\":\n",
    "    print('The transcription has errored out!')\n",
    "    break\n",
    "\n",
    "  else:\n",
    "    print(status)\n",
    "    time.sleep(2)\n",
    "    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
